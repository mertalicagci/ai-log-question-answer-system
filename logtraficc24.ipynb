{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHq8I6l7AaSPDYQ5NCzsO/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mertalicagci/ai-log-question-answer-system/blob/main/logtraficc24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMZ4X3IYgw8n",
        "outputId": "34bc98d6-00af-4546-de6b-0531cd6db1c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What pages returned a 200 status?\n",
            "Answer:\n",
            "Pages that returned a 200 status: GET /index.html HTTP/1.1, POST /login HTTP/1.1, GET /contact.html HTTP/1.1\n",
            "Getirilen Loglar:\n",
            "  IP_Adresi                      Istek  Durum_Kodu  Boyut\n",
            "192.168.1.1   GET /index.html HTTP/1.1         200   1234\n",
            "192.168.1.2       POST /login HTTP/1.1         200    567\n",
            "192.168.1.3   GET /about.html HTTP/1.1         404      0\n",
            "192.168.1.4 GET /contact.html HTTP/1.1         200    234\n",
            "Response Time: 0.0125 seconds\n",
            "\n",
            "Question: Which IP address accessed /login?\n",
            "Answer:\n",
            "The IP address that accessed the /login page is: 192.168.1.2\n",
            "Getirilen Loglar:\n",
            "  IP_Adresi                      Istek  Durum_Kodu  Boyut\n",
            "192.168.1.2       POST /login HTTP/1.1         200    567\n",
            "192.168.1.1   GET /index.html HTTP/1.1         200   1234\n",
            "192.168.1.4 GET /contact.html HTTP/1.1         200    234\n",
            "192.168.1.3   GET /about.html HTTP/1.1         404      0\n",
            "Response Time: 0.0124 seconds\n",
            "\n",
            "Question: Which pages were not found?\n",
            "Answer:\n",
            "Pages that returned a 404 status: GET /about.html HTTP/1.1\n",
            "Getirilen Loglar:\n",
            "  IP_Adresi                      Istek  Durum_Kodu  Boyut\n",
            "192.168.1.1   GET /index.html HTTP/1.1         200   1234\n",
            "192.168.1.2       POST /login HTTP/1.1         200    567\n",
            "192.168.1.3   GET /about.html HTTP/1.1         404      0\n",
            "192.168.1.4 GET /contact.html HTTP/1.1         200    234\n",
            "Response Time: 0.0137 seconds\n",
            "\n",
            "Question: Which pages returned the highest response size?\n",
            "Answer:\n",
            "Pages that returned the highest response size: GET /index.html HTTP/1.1\n",
            "Getirilen Loglar:\n",
            "  IP_Adresi                      Istek  Durum_Kodu  Boyut\n",
            "192.168.1.1   GET /index.html HTTP/1.1         200   1234\n",
            "192.168.1.2       POST /login HTTP/1.1         200    567\n",
            "192.168.1.3   GET /about.html HTTP/1.1         404      0\n",
            "192.168.1.4 GET /contact.html HTTP/1.1         200    234\n",
            "Response Time: 0.0061 seconds\n",
            "\n",
            "Average Response Time: 0.0112 seconds\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import faiss\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import time\n",
        "\n",
        "# Log verileri\n",
        "log_verileri = \"\"\"\n",
        "192.168.1.1 - - [10/Aug/2024:14:55:36 +0000] \"GET /index.html HTTP/1.1\" 200 1234\n",
        "192.168.1.2 - - [10/Aug/2024:14:56:02 +0000] \"POST /login HTTP/1.1\" 200 567\n",
        "192.168.1.3 - - [10/Aug/2024:14:57:10 +0000] \"GET /about.html HTTP/1.1\" 404 0\n",
        "192.168.1.4 - - [10/Aug/2024:14:57:50 +0000] \"GET /contact.html HTTP/1.1\" 200 234\n",
        "\"\"\"\n",
        "\n",
        "# Log verilerini satırlara ayır\n",
        "log_satirlari = log_verileri.strip().split('\\n')\n",
        "\n",
        "# RegEx desenini tek satırda tanımla\n",
        "log_pattern = r'(\\S+) - - \\[.*?\\] \"(.*?)\" (\\d{3}) (\\d+)'\n",
        "log_girisleri = []\n",
        "\n",
        "for satir in log_satirlari:\n",
        "    eslesen = re.match(log_pattern, satir)\n",
        "    if eslesen:\n",
        "        ip_adresi, istek, durum_kodu, boyut = eslesen.groups()\n",
        "        log_girisleri.append([ip_adresi, istek, int(durum_kodu), int(boyut)])\n",
        "\n",
        "# DataFrame oluştur\n",
        "df = pd.DataFrame(log_girisleri, columns=['IP_Adresi', 'Istek', 'Durum_Kodu', 'Boyut'])\n",
        "print(df)\n",
        "\n",
        "# TF-IDF Vectorizer ayarla\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['Istek'])\n",
        "\n",
        "# FAISS dizini oluştur\n",
        "dimension = X.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(X.toarray().astype('float32'))\n",
        "\n",
        "# T5 modelini yükle\n",
        "model_name = 't5-small'\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Sorguları çalıştır\n",
        "sorgular = [\n",
        "    'What pages returned a 200 status?',\n",
        "    'Which IP address accessed /login?',\n",
        "    'Which pages were not found?',\n",
        "    'Which pages returned the highest response size?'\n",
        "]\n",
        "\n",
        "start_time = time.time()\n",
        "for sorgu in sorgular:\n",
        "    inputs = tokenizer.encode(sorgu, return_tensors='pt')\n",
        "    outputs = model.generate(inputs)\n",
        "    cevap = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(f'Question: {sorgu}')\n",
        "    print(f'Answer: {cevap}')\n",
        "\n",
        "end_time = time.time()\n",
        "print(f'Response Time: {end_time - start_time} seconds')"
      ]
    }
  ]
}
