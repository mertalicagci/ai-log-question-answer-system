{
  "cell_type": "code",
  "execution_count": 3,
  "metadata": {
    "colab": {
      "base_uri": "https://localhost:8080/"
    },
    "id": "ZMZ4X3IYgw8n",
    "outputId": "34bc98d6-00af-4546-de6b-0531cd6db1c1"
  },
  "outputs": [
    {
      "output_type": "stream",
      "name": "stdout",
      "text": [
        "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
        "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
        "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n"
      ]
    },
    {
      "output_type": "stream",
      "name": "stderr",
      "text": [
        "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
      ]
    },
    {
      "output_type": "stream",
      "name": "stdout",
      "text": [
        "Question: What pages returned a 200 status?\n",
        "Answer:\n",
        "Pages that returned a 200 status: GET /index.html HTTP/1.1, POST /login HTTP/1.1, GET /contact.html HTTP/1.1\n",
        "Getirilen Loglar:\n",
        "  IP_Adresi                      Istek  Durum_Kodu  Boyut\n",
        "192.168.1.1   GET /index.html HTTP/1.1         200   1234\n",
        "192.168.1.2       POST /login HTTP/1.1         200    567\n",
        "192.168.1.3   GET /about.html HTTP/1.1         404      0\n",
        "192.168.1.4 GET /contact.html HTTP/1.1         200    234\n",
        "Response Time: 0.0125 seconds\n",
        "\n",
        "Question: Which IP address accessed /login?\n",
        "Answer:\n",
        "The IP address that accessed the /login page is: 192.168.1.2\n",
        "Getirilen Loglar:\n",
        "  IP_Adresi                      Istek  Durum_Kodu  Boyut\n",
        "192.168.1.2       POST /login HTTP/1.1         200    567\n",
        "192.168.1.1   GET /index.html HTTP/1.1         200   1234\n",
        "192.168.1.4 GET /contact.html HTTP/1.1         200    234\n",
        "192.168.1.3   GET /about.html HTTP/1.1         404      0\n",
        "Response Time: 0.0124 seconds\n",
        "\n",
        "Question: Which pages were not found?\n",
        "Answer:\n",
        "Pages that returned a 404 status: GET /about.html HTTP/1.1\n",
        "Getirilen Loglar:\n",
        "  IP_Adresi                      Istek  Durum_Kodu  Boyut\n",
        "192.168.1.1   GET /index.html HTTP/1.1         200   1234\n",
        "192.168.1.2       POST /login HTTP/1.1         200    567\n",
        "192.168.1.3   GET /about.html HTTP/1.1         404      0\n",
        "192.168.1.4 GET /contact.html HTTP/1.1         200    234\n",
        "Response Time: 0.0137 seconds\n",
        "\n",
        "Question: Which pages returned the highest response size?\n",
        "Answer:\n",
        "Pages that returned the highest response size: GET /index.html HTTP/1.1\n",
        "Getirilen Loglar:\n",
        "  IP_Adresi                      Istek  Durum_Kodu  Boyut\n",
        "192.168.1.1   GET /index.html HTTP/1.1         200   1234\n",
        "192.168.1.2       POST /login HTTP/1.1         200    567\n",
        "192.168.1.3   GET /about.html HTTP/1.1         404      0\n",
        "192.168.1.4 GET /contact.html HTTP/1.1         200    234\n",
        "Response Time: 0.0061 seconds\n",
        "\n",
        "Average Response Time: 0.0112 seconds\n"
      ]
    }
  ],
  "source": [
    "!pip install faiss-cpu\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import faiss\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import time\n",
    "\n",
    "# Log verileri\n",
    "log_verileri = \"\"\"\n",
    "192.168.1.1 - - [10/Aug/2024:14:55:36 +0000] \"GET /index.html HTTP/1.1\" 200 1234\n",
    "192.168.1.2 - - [10/Aug/2024:14:56:02 +0000] \"POST /login HTTP/1.1\" 200 567\n",
    "192.168.1.3 - - [10/Aug/2024:14:57:10 +0000] \"GET /about.html HTTP/1.1\" 404 0\n",
    "192.168.1.4 - - [10/Aug/2024:14:57:50 +0000] \"GET /contact.html HTTP/1.1\" 200 234\n",
    "\"\"\"\n",
    "\n",
    "# Log verilerini satırlara ayır\n",
    "log_satirlari = log_verileri.strip().split('\\n')\n",
    "\n",
    "# RegEx desenini tek satırda tanımla\n",
    "log_pattern = r'(\\S+) - - \\[.*?\\] \"(.*?)\" (\\d{3}) (\\d+)'\n",
    "log_girisleri = []\n",
    "\n",
    "for satir in log_satirlari:\n",
    "    eslesen = re.match(log_pattern, satir)\n",
    "    if eslesen:\n",
    "        ip_adresi, istek, durum_kodu, boyut = eslesen.groups()\n",
    "        log_girisleri.append([ip_adresi, istek, int(durum_kodu), int(boyut)])\n",
    "\n",
    "# DataFrame oluştur\n",
    "log_df = pd.DataFrame(log_girisleri, columns=['IP_Adresi', 'Istek', 'Durum_Kodu', 'Boyut'])\n",
    "\n",
    "# Veri temizleme\n",
    "log_df = log_df.dropna()\n",
    "log_df = log_df[log_df['IP_Adresi'].str.match(r'\\d+\\.\\d+\\.\\d+\\.\\d+')]\n",
    "log_df['Boyut'] = log_df['Boyut'].astype(int)\n",
    "\n",
    "# 'Istek' sütununu vektörize et\n",
    "vektorleyici = TfidfVectorizer()\n",
    "istek_vektorleri = vektorleyici.fit_transform(log_df['Istek']).toarray()\n",
    "\n",
    "# FAISS endiksi oluştur\n",
    "boyut = istek_vektorleri.shape[1]\n",
    "faiss_endiksi = faiss.IndexFlatL2(boyut)\n",
    "\n",
    "# Vektörleri FAISS endeksine ekle\n",
    "faiss_endiksi.add(istek_vektorleri)\n",
    "\n",
    "# T5 modelini yükle\n",
    "model_adi = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_adi, legacy=False)  # Yeni davranış biçimini kullan\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_adi)\n",
    "\n",
    "def cevap_olustur(soru, log_df, faiss_endeksi, vektorleyici, tokenizer, model, k=1):\n",
    "    vektör = vektorleyici.transform([soru]).toarray()\n",
    "    _, idx = faiss_endeksi.search(vektör, k)\n",
    "    en_uygun_kayitlar = log_df.iloc[idx[0]]\n",
    "    yanit = ''\n",
    "    for _, satir in en_uygun_kayitlar.iterrows():\n",
    "        metin = f'IP Adresi: {satir['IP_Adresi']}, İstek: {satir['Istek']}, Durum Kodu: {satir['Durum_Kodu']}, Boyut: {satir['Boyut']}'\n",
    "        yanit += metin + '\\n'\n",
    "    input_ids = tokenizer.encode(yanit, return_tensors='pt')\n",
    "    output_ids = model.generate(input_ids)\n",
    "    yanit = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return yanit\n",
    "\n",
    "soru = 'Which pages returned the highest response size?'\n",
    "yanit = cevap_olustur(soru, log_df, faiss_endiksi, vektorleyici, tokenizer, model)\n",
    "print(f'Soru: {soru}')\n",
    "print(f'Yanıt: {yanit}')\n"
  ]
}
