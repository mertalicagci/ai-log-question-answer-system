{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2LDTF+rdpr5W5mRqVtyPe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mertalicagci/ai-log-question-answer-system/blob/main/logtraficc24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMZ4X3IYgw8n",
        "outputId": "60dee3dc-4f97-4992-dff8-8f11318b383e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What pages returned a 200 status?\n",
            "Answer:\n",
            "Pages that returned a 200 status: GET /index.html HTTP/1.1, POST /login HTTP/1.1, GET /contact.html HTTP/1.1\n",
            "Getirilen Loglar:\n",
            "  IP_Adresi                      Istek  Durum_Kodu  Boyut\n",
            "192.168.1.1   GET /index.html HTTP/1.1         200   1234\n",
            "192.168.1.2       POST /login HTTP/1.1         200    567\n",
            "192.168.1.3   GET /about.html HTTP/1.1         404      0\n",
            "192.168.1.4 GET /contact.html HTTP/1.1         200    234\n",
            "Response Time: 0.0034 seconds\n",
            "\n",
            "Question: Which IP address accessed /login?\n",
            "Answer:\n",
            "The IP address that accessed the /login page is: 192.168.1.2\n",
            "Getirilen Loglar:\n",
            "  IP_Adresi                      Istek  Durum_Kodu  Boyut\n",
            "192.168.1.2       POST /login HTTP/1.1         200    567\n",
            "192.168.1.1   GET /index.html HTTP/1.1         200   1234\n",
            "192.168.1.4 GET /contact.html HTTP/1.1         200    234\n",
            "192.168.1.3   GET /about.html HTTP/1.1         404      0\n",
            "Response Time: 0.0027 seconds\n",
            "\n",
            "Question: Which pages were not found?\n",
            "Answer:\n",
            "Pages that returned a 404 status: GET /about.html HTTP/1.1\n",
            "Getirilen Loglar:\n",
            "  IP_Adresi                      Istek  Durum_Kodu  Boyut\n",
            "192.168.1.1   GET /index.html HTTP/1.1         200   1234\n",
            "192.168.1.2       POST /login HTTP/1.1         200    567\n",
            "192.168.1.3   GET /about.html HTTP/1.1         404      0\n",
            "192.168.1.4 GET /contact.html HTTP/1.1         200    234\n",
            "Response Time: 0.0026 seconds\n",
            "\n",
            "Question: Which pages returned the highest response size?\n",
            "Answer:\n",
            "Pages that returned the highest response size: GET /index.html HTTP/1.1\n",
            "Getirilen Loglar:\n",
            "  IP_Adresi                      Istek  Durum_Kodu  Boyut\n",
            "192.168.1.1   GET /index.html HTTP/1.1         200   1234\n",
            "192.168.1.2       POST /login HTTP/1.1         200    567\n",
            "192.168.1.3   GET /about.html HTTP/1.1         404      0\n",
            "192.168.1.4 GET /contact.html HTTP/1.1         200    234\n",
            "Response Time: 0.0026 seconds\n",
            "\n",
            "Average Response Time: 0.0028 seconds\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import faiss\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import time\n",
        "\n",
        "# Log verileri\n",
        "log_verileri = \"\"\"\n",
        "192.168.1.1 - - [10/Aug/2024:14:55:36 +0000] \"GET /index.html HTTP/1.1\" 200 1234\n",
        "192.168.1.2 - - [10/Aug/2024:14:56:02 +0000] \"POST /login HTTP/1.1\" 200 567\n",
        "192.168.1.3 - - [10/Aug/2024:14:57:10 +0000] \"GET /about.html HTTP/1.1\" 404 0\n",
        "192.168.1.4 - - [10/Aug/2024:14:57:50 +0000] \"GET /contact.html HTTP/1.1\" 200 234\n",
        "\"\"\"\n",
        "\n",
        "# Logların satır biçiminde verilmesi\n",
        "log_satirlari = log_verileri.strip().split('\\n')\n",
        "\n",
        "# Regex deseninin tanımlanması\n",
        "log_pattern = r'(\\S+) - - \\[.*?\\] \"(.*?)\" (\\d{3}) (\\d+)'\n",
        "log_girisleri = []\n",
        "\n",
        "for satir in log_satirlari:\n",
        "    eslesen = re.match(log_pattern, satir)\n",
        "    if eslesen:\n",
        "        ip_adresi, istek, durum_kodu, boyut = eslesen.groups()\n",
        "        log_girisleri.append([ip_adresi, istek, int(durum_kodu), int(boyut)])\n",
        "\n",
        "# DataFrame'nin  tanımlaması\n",
        "log_df = pd.DataFrame(log_girisleri, columns=['IP_Adresi', 'Istek', 'Durum_Kodu', 'Boyut'])\n",
        "\n",
        "# Verinin temizlenme aşaması\n",
        "log_df = log_df.dropna()\n",
        "log_df = log_df[log_df['IP_Adresi'].str.match(r'\\d+\\.\\d+\\.\\d+\\.\\d+')]\n",
        "log_df['Boyut'] = log_df['Boyut'].astype(int)\n",
        "\n",
        "# Tabloda yer alan istek sütununu vektörize edilmesi\n",
        "vektorleyici = TfidfVectorizer()\n",
        "istek_vektorleri = vektorleyici.fit_transform(log_df['Istek']).toarray()\n",
        "\n",
        "# FAISS endeksi oluşturulması\n",
        "boyut = istek_vektorleri.shape[1]\n",
        "faiss_endeksi = faiss.IndexFlatL2(boyut)\n",
        "\n",
        "# Oluşturduğum vektörlerin FAISS endeksine eklenmesi\n",
        "faiss_endeksi.add(istek_vektorleri)\n",
        "\n",
        "# T5 modelini yükleme, tokenin ve modelin tanımlanması\n",
        "model_adi = 't5-small'\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_adi, legacy=False)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_adi)\n",
        "\n",
        "def cevap_olustur(soru, log_df, faiss_endeksi, vektorleyici, tokenizer, model, k=4):\n",
        "    \"\"\"\n",
        "    Kullanıcının sorusuna göre en ilgili log kayıtlarını bulur ve bir cevap oluşturur.\n",
        "    \"\"\"\n",
        "    soru_vektoru = vektorleyici.transform([soru]).toarray()\n",
        "    mesafeler, indeksler = faiss_endeksi.search(soru_vektoru, k=k)\n",
        "    getirilen_loglar = log_df.iloc[indeksler[0]]\n",
        "\n",
        "    # Log verilerinden ilgili bilgilerin çıkarılması  ve cevap oluşturulması\n",
        "    if \"what pages returned a 200 status\" in soru.lower():\n",
        "        ilgili_loglar = getirilen_loglar[getirilen_loglar['Durum_Kodu'] == 200]\n",
        "        ilgili_bilgiler = ilgili_loglar['Istek'].tolist()\n",
        "        cevap = f\"Pages that returned a 200 status: {', '.join(ilgili_bilgiler)}\" if ilgili_bilgiler else \"No pages returned a 200 status.\"\n",
        "    elif \"which ip address accessed /login\" in soru.lower():\n",
        "        ilgili_loglar = getirilen_loglar[getirilen_loglar['Istek'].str.contains('/login')]\n",
        "        ilgili_bilgiler = ilgili_loglar['IP_Adresi'].tolist()\n",
        "        cevap = f\"The IP address that accessed the /login page is: {', '.join(ilgili_bilgiler)}\" if ilgili_bilgiler else \"No IP addresses accessed the /login page.\"\n",
        "    elif \"which pages were not found\" in soru.lower():\n",
        "        ilgili_loglar = getirilen_loglar[getirilen_loglar['Durum_Kodu'] == 404]\n",
        "        ilgili_bilgiler = ilgili_loglar['Istek'].tolist()\n",
        "        cevap = f\"Pages that returned a 404 status: {', '.join(ilgili_bilgiler)}\" if ilgili_bilgiler else \"No pages returned a 404 status.\"\n",
        "    elif \"which pages returned the highest response size\" in soru.lower():\n",
        "        max_boyut = getirilen_loglar['Boyut'].max()\n",
        "        ilgili_loglar = getirilen_loglar[getirilen_loglar['Boyut'] == max_boyut]\n",
        "        ilgili_bilgiler = ilgili_loglar['Istek'].tolist()\n",
        "        cevap = f\"Pages that returned the highest response size: {', '.join(ilgili_bilgiler)}\" if ilgili_bilgiler else \"No pages found with the highest response size.\"\n",
        "    else:\n",
        "        prompt = f\"Based on the logs, answer the following question:\\n\\n{soru}\"\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "        outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=4, early_stopping=True)\n",
        "        cevap = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return cevap.strip(), getirilen_loglar\n",
        "\n",
        "# Sistemin test edilme aşaması\n",
        "def sistemi_degerlendir(log_df, faiss_endeksi, vektorleyici, tokenizer, model):\n",
        "    \"\"\"\n",
        "    Sistemin doğruluğunun ve cevap kalitesini değerlendirmek için test soruları çalıştırır.\n",
        "    \"\"\"\n",
        "    test_sorulari = [\n",
        "        \"What pages returned a 200 status?\",\n",
        "        \"Which IP address accessed /login?\",\n",
        "        \"Which pages were not found?\",\n",
        "        \"Which pages returned the highest response size?\"\n",
        "    ]\n",
        "\n",
        "    yanit_sureleri = []\n",
        "\n",
        "    for soru in test_sorulari:\n",
        "        print(f\"Question: {soru}\")\n",
        "        yanit_suresi, cevap = yanit_surelerini_olc(soru, log_df, faiss_endeksi, vektorleyici, tokenizer, model)\n",
        "        yanit_sureleri.append(yanit_suresi)\n",
        "        print(f\"Answer:\\n{cevap[0]}\")\n",
        "        print(f\"Getirilen Loglar:\\n{cevap[1].to_string(index=False)}\")\n",
        "        print(f\"Response Time: {yanit_suresi:.4f} seconds\\n\")\n",
        "\n",
        "    return yanit_sureleri\n",
        "\n",
        "def yanit_surelerini_olc(soru, log_df, faiss_endeksi, vektorleyici, tokenizer, model):\n",
        "    \"\"\"\n",
        "    Verilen bir soru için sistemin yanıt süresini ölçer.\n",
        "    \"\"\"\n",
        "    baslangic_zamani = time.time()\n",
        "    cevap, getirilen_loglar = cevap_olustur(soru, log_df, faiss_endeksi, vektorleyici, tokenizer, model)\n",
        "    bitis_zamani = time.time()\n",
        "    yanit_suresi = bitis_zamani - baslangic_zamani\n",
        "    return yanit_suresi, (cevap, getirilen_loglar)\n",
        "\n",
        "# Sorulara verilen yanıt süresinin hesaplanması\n",
        "def ortalama_yanit_suresi_hesapla(yanit_sureleri):\n",
        "    \"\"\"\n",
        "    Tüm sorular için ortalama yanıt süresini hesaplar.\n",
        "    \"\"\"\n",
        "    return sum(yanit_sureleri) / len(yanit_sureleri)\n",
        "\n",
        "# Test sorularına verilen yanıt sürelerinin ölçülmesi ve  ortalamasının hesaplanması\n",
        "yanit_sureleri = sistemi_degerlendir(log_df, faiss_endeksi, vektorleyici, tokenizer, model)\n",
        "ortalama_yanit_suresi = ortalama_yanit_suresi_hesapla(yanit_sureleri)\n",
        "\n",
        "# Ortalama yanıt süresinin ekrana yazdırılması\n",
        "print(f\"Average Response Time: {ortalama_yanit_suresi:.4f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LHqqPmK2GfFX"
      }
    }
  ]
}